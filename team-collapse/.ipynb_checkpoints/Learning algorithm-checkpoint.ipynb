{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d78160",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7a5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_players = 5\n",
    "players = [f'player{i}' for i in range(1, N_players+1)]\n",
    "n_components = 3 # num of hidden states\n",
    "n_features = 3 # num of observed states\n",
    "O_symbols = [0, 1, 2] # under-, avg-, over- performance\n",
    "H_symbols = [0, 1, 2] # corresponding mental states\n",
    "T = 100\n",
    "learning_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87682383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamModel:\n",
    "    def __init__(self, initial_dist, M, N, R, emission_prob):\n",
    "        self.initial_dist = initial_dist\n",
    "        \n",
    "        # Transition matrices\n",
    "        self.M = M # dictionary. key = player, value = a row-stochastic matrix, observation-to-state transitions\n",
    "        self.N = N # dictionary. key = player, value = a row-stochastic matrix, state-to-state transitions\n",
    "        \n",
    "        # Graph weights - Tie strengh\n",
    "        self.R = R # row-stochastic matrix\n",
    "        \n",
    "        # Emission matrices\n",
    "        self.emission_prob = emission_prob # for each player, a row-stochastic matrix\n",
    "        \n",
    "        # Store latest hidden and observed states\n",
    "        self.H = None\n",
    "        self.O = None\n",
    "    \n",
    "        self.t = 0\n",
    "   \n",
    "    def check_input_parameters(self):\n",
    "        pass\n",
    "    \n",
    "    def next(self):\n",
    "        if self.t == 0:\n",
    "            self.H = {p: np.random.choice(H_symbols, p=self.initial_dist) for p in players}\n",
    "            self.O = {p: np.random.choice(O_symbols, p=self.emission_prob[p][self.H[p]]) for p in players}\n",
    "            self.t = 1\n",
    "            \n",
    "            return self.H, self.O\n",
    "            \n",
    "        H_new = {}\n",
    "        O_new = {}\n",
    "        for p in players:\n",
    "            R_ = self.R[p]\n",
    "            emission_ = self.emission_prob[p]\n",
    "            \n",
    "            # produce next hidden state\n",
    "            dist = []\n",
    "            for h in H_symbols: # calculate the probability of each next state h\n",
    "                v = []\n",
    "                v.append(self.N[p][self.H[p]][h]) # P(H_t^player = h | H__{t-1}^player = H[player])\n",
    "                for teammate in players:\n",
    "                    if (p, teammate) in M:\n",
    "                        v.append(self.M[(p, teammate)][self.O[teammate]][h]) # P(H_t^player = h | O_{t-1}^teammate = O[teammate])\n",
    "                    else:\n",
    "                        v.append(self.M[p][self.O[teammate]][h])\n",
    "                v = np.array(v)\n",
    "                \n",
    "                dist.append(np.dot(R_, v))\n",
    "            \n",
    "            h_new = np.random.choice(H_symbols, p=dist)\n",
    "            \n",
    "            # produce next observation\n",
    "            o_new = np.random.choice(O_symbols, p=emission_[h_new])\n",
    "            \n",
    "            # Add new values to\n",
    "            H_new[p] = h_new\n",
    "            O_new[p] = o_new\n",
    "            \n",
    "        # Update hidden and observed states\n",
    "        self.H = H_new\n",
    "        self.O = O_new\n",
    "        \n",
    "        # Update time\n",
    "        self.t += 1\n",
    "        \n",
    "        return H_new, O_new\n",
    "    \n",
    "    def get_data(self, T = 1000):\n",
    "        # T = number of observations (i.e. number of iterations)\n",
    "        self.restart()\n",
    "        data = []\n",
    "        for _ in range(T):\n",
    "            H, O = self.next()\n",
    "            data.append((H, O))\n",
    "        return data\n",
    "    \n",
    "    def restart(self):\n",
    "        self.H = None\n",
    "        self.O = None\n",
    "        self.t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc928df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === M ===\n",
    "avg_transO = np.array([[0.5, 0.3, 0.2],\n",
    "                       [0.25, 0.5, 0.25],\n",
    "                       [0.2, 0.3, 0.5]])\n",
    "\n",
    "star_transO = np.array([[0.7, 0.3, 0],\n",
    "                        [0.2, 0.6, 0.2],\n",
    "                        [0, 0.3, 0.7]])\n",
    "# === N ===\n",
    "avg_transH = np.array([[0.7, 0.3, 0.0],\n",
    "                       [0.2, 0.6, 0.2],\n",
    "                       [0.0, 0.3, 0.7]])\n",
    "\n",
    "# === emission_prob ===\n",
    "avg_emission = np.array([[0.6, 0.3, 0.1],\n",
    "                       [0.2, 0.6, 0.2],\n",
    "                       [0.1, 0.3, 0.6]])\n",
    "\n",
    "# ===  R ===\n",
    "R_singleH = np.array([1] + [0] * len(players))\n",
    "def R_singleHO(player):\n",
    "    i = int(player[-1])\n",
    "    arr = [0] * (len(players)+1)\n",
    "    arr[0] = 0.7\n",
    "    arr[i] = 0.3\n",
    "    return np.array(arr)\n",
    "\n",
    "def R_singleO(player):\n",
    "    i = int(player[-1])\n",
    "    arr = [0] * (len(players)+1)\n",
    "    arr[i] = 1\n",
    "    return np.array(arr)\n",
    "\n",
    "def R_star(player, star):\n",
    "    if player == star:\n",
    "        return R_singleH\n",
    "    arr = [0] * (len(players)+1)\n",
    "    i = int(star[-1])\n",
    "    arr[i] = 1\n",
    "    return np.array(arr)\n",
    "    \n",
    "R_uniform = np.array([1/(1 + len(players))] * (len(players) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6b4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(model, T, seed=73):\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "    data = model.get_data(T)\n",
    "\n",
    "    # Store data\n",
    "    observations = {player: [] for player in players}\n",
    "    true_hidden = {player: [] for player in players}\n",
    "    for (h, o) in data:\n",
    "        for player in players:\n",
    "            true_hidden[player].append(h[player])\n",
    "            observations[player].append(o[player])\n",
    "\n",
    "    for player in players:\n",
    "        observations[player] = np.array(observations[player])\n",
    "        true_hidden[player] = np.array(true_hidden[player])\n",
    "    return observations, true_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adb149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = {player: star_transO for player in players}\n",
    "N = {player: avg_transH for player in players}\n",
    "emission_prob = {player: avg_emission for player in players}\n",
    "R = {player: R_star(player, 'player1') for player in players}\n",
    "initial_dist = np.array([0, 1, 0])\n",
    "\n",
    "model = TeamModel(initial_dist, M, N, R, emission_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9191d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "Os, Hs = generate_data(model, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c551c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_trans():\n",
    "    trans_mat = np.zeros((n_components, n_components))\n",
    "    \n",
    "    trans_mat[0][0] = np.random.uniform(0.5, 1)\n",
    "    trans_mat[0][1] = 1 - trans_mat[0][0]\n",
    "    trans_mat[0][2] = 0.0\n",
    "    \n",
    "    trans_mat[1][1] = np.random.uniform(0.5, 1)\n",
    "    trans_mat[1][0] = (1 - trans_mat[1][1]) / 2\n",
    "    trans_mat[1][2] = (1 - trans_mat[1][1]) / 2\n",
    "    \n",
    "    trans_mat[2][2] = np.random.uniform(0.5, 1)\n",
    "    trans_mat[2][0] = 0.0\n",
    "    trans_mat[2][1] = 1 - trans_mat[2][2]\n",
    "    \n",
    "    return trans_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be400ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond(player, h1, h2, t, M_, N_, R_): # P(H_t^player = h1 | H_{t-1}^player = h2, O_{t-1})    \n",
    "    # Requires M_, N_, R_, Os\n",
    "    v = [N_[h2][h1]]\n",
    "    for teammate in players:\n",
    "        v.append(M_[Os[teammate][t-1]][h1])\n",
    "            \n",
    "    v = np.array(v)\n",
    "    return np.dot(R_[player], v)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9cbd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_R(M, N, samples, O):\n",
    "    R = {p: cp.Variable(len(players) + 1, nonneg=True) for p in players}\n",
    "\n",
    "    objective = 0\n",
    "    for H in samples:\n",
    "        for p in players:\n",
    "            for t in range(1, T):\n",
    "                h_t = H[p][t] # state of player p at time t\n",
    "                v_t = [N[H[p][t-1]][h_t]]\n",
    "                for teammate in players:\n",
    "                    v_t.append(M[O[teammate][t-1]][h_t])\n",
    "                v_t = np.array(v_t)\n",
    "                prod = R[p] @ v_t\n",
    "                objective -= cp.log(prod)\n",
    "\n",
    "\n",
    "    constraints = [cp.sum(R[p]) == 1 for p in R]\n",
    "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    R_optimized = {p: R[p].value for p in players}\n",
    "\n",
    "    return R_optimized, prob.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8f7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_M_N(R, samples, O):\n",
    "    M = cp.Variable((n_features, n_components), nonneg=True)\n",
    "    N = cp.Variable((n_components, n_components), nonneg=True) \n",
    "\n",
    "    objective = 0\n",
    "    for H in samples:\n",
    "        for p in players:\n",
    "            for t in range(1, T):\n",
    "                h_t = H[p][t] # state of player p at time t\n",
    "                v_t = [N[H[p][t-1], h_t]]\n",
    "                for teammate in players:\n",
    "                    v_t.append(M[O[teammate][t-1], h_t])\n",
    "                v_t = np.array(v_t)\n",
    "                prod = R[p] @ v_t\n",
    "                objective -= cp.log(prod)\n",
    "\n",
    "\n",
    "    M_constraints = [cp.sum(M[i, :]) == 1 for i in range(n_features)]\n",
    "    N_constraints = [cp.sum(N[i, :]) == 1 for i in range(n_components)]\n",
    "\n",
    "    constraints = M_constraints + N_constraints\n",
    "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    M_optimized = M.value\n",
    "    N_optimized = N.value\n",
    "\n",
    "    return M_optimized, N_optimized, prob.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80479c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_E():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c069f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forward(M_, N_, E_, R_):\n",
    "    alpha = {p: [] for p in players}\n",
    "    alpha_help = {p: [] for p in players}\n",
    "    \n",
    "    # Initialize forward parameters\n",
    "    for p in players:\n",
    "        alpha_help[p].append(initial_dist)\n",
    "    for p in players:\n",
    "        arr = np.array([E_[p][h][Os[p][0]] * alpha_help[p][0][h] for h in H_symbols])\n",
    "        arr /= np.sum(arr)\n",
    "        alpha[p].append(arr)\n",
    "\n",
    "    # Compute forward parameters (bottom-up)\n",
    "    for p in players:\n",
    "        for t in range(1, T):\n",
    "            arr = [sum([cond(p, h, h_, t, M_, N_, R_) * alpha[p][t-1][h_] for h_ in H_symbols]) for h in H_symbols]\n",
    "            arr = np.array(arr)\n",
    "            alpha_help[p].append(arr)\n",
    "            \n",
    "            arr = [E_[p][h][Os[p][t]] * alpha_help[p][t][h] for h in H_symbols]\n",
    "            arr = np.array(arr)\n",
    "            arr /= np.sum(arr)\n",
    "            alpha[p].append(arr)\n",
    "            \n",
    "    return alpha, alpha_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab61922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(M_, N_, E_, R_, num_of_samples = 10):\n",
    "    alpha, alpha_help = calculate_forward(M_, N_, E_, R_)\n",
    "    \n",
    "    # Sample hidden states from the posterior distribution\n",
    "    samples = []\n",
    "    for _ in range(num_of_samples):\n",
    "        Hs_ = {p: [1] for p in players}\n",
    "\n",
    "        for p in players:\n",
    "            for t in range(1, T):\n",
    "                dist = np.array([alpha[p][t][h] * cond(p, h, Hs_[p][t-1], t, M_, N_, R_) / alpha_help[p][t][h] if alpha_help[p][t][h] != 0 else 0 for h in H_symbols])\n",
    "                dist /= np.sum(dist)\n",
    "                Hs_[p].append(np.random.choice(H_symbols, p=dist))\n",
    "        for p in players:\n",
    "            Hs_[p] = np.array(Hs_[p])\n",
    "        samples.append(copy.deepcopy(Hs_))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def M_step(samples, M, N, R, iterations=1):\n",
    "#     M_opt = copy.deepcopy(M)\n",
    "#     N_opt = copy.deepcopy(N)\n",
    "    M_opt = M\n",
    "    N_opt = N\n",
    "    R_opt = copy.deepcopy(R)\n",
    "    for _ in range(iterations):\n",
    "        try:\n",
    "            # Fix M, N and maximize R\n",
    "            R_opt, val = learn_R(M_opt, N_opt, samples, Os)\n",
    "            \n",
    "            # Fix R and maximize M, N\n",
    "            M_opt, N_opt, val = learn_M_N(R_opt, samples, Os)\n",
    "            \n",
    "                \n",
    "            print(f'\\tObj = {val}')            \n",
    "        except cp.error.SolverError as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "    return M_opt, N_opt, R_opt, val\n",
    "\n",
    "def EM(params, iterations = 50, reltol = 1e-3):\n",
    "    # Initialize parameters\n",
    "    M_, N_, E_, R_ = params['M'], params['N'], params['E'], params['R']\n",
    "   \n",
    "    \n",
    "    val = 1e+100 # best objective value achieved so far\n",
    "    M_opt = M_\n",
    "    N_opt = N_\n",
    "    E_opt = E_\n",
    "    R_opt = R_\n",
    "    for i in range(iterations):\n",
    "        print(f'=== EM iteration {i+1} ===')\n",
    "        # E-step\n",
    "        print(f'E-step...')\n",
    "        samples = E_step(M_, N_, E_, R_)\n",
    "        \n",
    "        # M-step\n",
    "        print(f'M-step...')\n",
    "        M_, N_, R_, obj_val = M_step(samples, M_, N_, R_)\n",
    "        \n",
    "        if (val - obj_val) / val < reltol:\n",
    "            break\n",
    "        if obj_val < val:\n",
    "            # Store current best parameters\n",
    "            M_opt = M_\n",
    "            N_opt = N_\n",
    "            E_opt = E_\n",
    "            R_opt = R_\n",
    "            \n",
    "        val = min(val, obj_val)\n",
    "        \n",
    "    return M_opt, N_opt, R_opt, E_opt, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31af4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_helper(param_list):\n",
    "    val_opt = 1e+100\n",
    "    for params in param_list:\n",
    "        M_, N_, R_, E_, val = EM(params)\n",
    "        \n",
    "        if val < val_opt:\n",
    "            val_opt = val\n",
    "            M_opt = M_\n",
    "            N_opt = N_\n",
    "            E_opt = E_\n",
    "            R_opt = R_\n",
    "            \n",
    "    return M_opt, N_opt, E_opt, R_opt, val_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0492a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EM iteration 1 ===\n",
      "E-step...\n",
      "M-step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr3/graduate/nikolaou/.local/lib/python3.10/site-packages/cvxpy/problems/problem.py:157: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tObj = 2138.213252850518\n",
      "{'player1': array([1., 0., 0., 0., 0., 0.]), 'player2': array([0., 1., 0., 0., 0., 0.]), 'player3': array([0.        , 0.98936907, 0.        , 0.01063093, 0.        ,\n",
      "       0.        ]), 'player4': array([0.00000000e+00, 9.99999970e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.07895019e-08, 0.00000000e+00]), 'player5': array([0., 1., 0., 0., 0., 0.])}\n",
      "=== EM iteration 2 ===\n",
      "E-step...\n",
      "M-step...\n",
      "\tObj = 2132.821242465801\n",
      "{'player1': array([0.95993052, 0.        , 0.03778003, 0.        , 0.00228945,\n",
      "       0.        ]), 'player2': array([0., 1., 0., 0., 0., 0.]), 'player3': array([0.        , 0.98675009, 0.        , 0.01324991, 0.        ,\n",
      "       0.        ]), 'player4': array([0.        , 0.99088377, 0.        , 0.00911623, 0.        ,\n",
      "       0.        ]), 'player5': array([0.        , 0.99463005, 0.00536995, 0.        , 0.        ,\n",
      "       0.        ])}\n",
      "=== EM iteration 3 ===\n",
      "E-step...\n",
      "M-step...\n",
      "\tObj = 2190.3441993623774\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "M_ = init_trans()\n",
    "N_ = init_trans()\n",
    "E_ = emission_prob\n",
    "R_ = {p: R_star(p, 'player1') for p in players}\n",
    "M_, N_, R_, val = EM(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9c81e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player1': array([0.87802794, 0.04997556, 0.04983815, 0.01555951, 0.00659883,\n",
       "        0.        ]),\n",
       " 'player2': array([0., 1., 0., 0., 0., 0.]),\n",
       " 'player3': array([0.        , 0.98281519, 0.        , 0.01718481, 0.        ,\n",
       "        0.        ]),\n",
       " 'player4': array([0.        , 0.97907743, 0.        , 0.01214694, 0.00877563,\n",
       "        0.        ]),\n",
       " 'player5': array([0.        , 0.99345375, 0.00551681, 0.        , 0.00102944,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6bcd290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76874358, 0.23125643, 0.        ],\n",
       "       [0.00762495, 0.97618851, 0.01618654],\n",
       "       [0.        , 0.13819118, 0.86180882]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b8eb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.93501569e-01, 3.06498430e-01, 0.00000000e+00],\n",
       "       [2.38238715e-01, 5.33317401e-01, 2.28443879e-01],\n",
       "       [9.71880021e-10, 4.66905482e-01, 5.33094517e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c3886a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(params): # Calculate log P(O) (given the model parameters)\n",
    "    M, N, E, R = params['M'], params['N'], params['E'], params['R']\n",
    "\n",
    "    # Caluclate forward parameters\n",
    "    alpha, alpha_help = calculate_forward(M, N, E, R)\n",
    "    obj = 0\n",
    "    for p in players:\n",
    "        for t in range(T):\n",
    "            obj += -np.log(sum([E[p][h][Os[p][t]] * alpha_help[p][t][h] for h in H_symbols])) # Pr(O_t^i | O_{1:t-1})\n",
    "    return obj\n",
    "\n",
    "def likelihood_test(params_list):\n",
    "    # Given a list of model parameters returns the model parameters that achieve the highest likelihood\n",
    "    val_opt = 1e+100\n",
    "    for params in params_list:\n",
    "        val = likelihood(params)\n",
    "        if val < val_opt:\n",
    "            val_opt = val\n",
    "            params_opt = params\n",
    "    return params_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f45573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570.4552441987914"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_ = {p: R_singleO(p) for p in players}\n",
    "likelihood(M[p], N[p], emission_prob, R_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b297cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b6d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
